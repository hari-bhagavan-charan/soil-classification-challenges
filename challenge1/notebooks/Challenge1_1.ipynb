{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Essential imports for soil image analysis\n",
        "import numpy as np                     # Matrix operations\n",
        "import pandas as pd                    # Data handling\n",
        "import os                              # File system operations\n",
        "import matplotlib.pyplot as plt        # Plotting\n",
        "from PIL import Image                  # Image processing\n",
        "\n",
        "# Deep learning framework components\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "\n",
        "# Model evaluation tools\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Utility imports\n",
        "from tqdm import tqdm                  # Progress visualization\n",
        "import copy                            # Model state preservation\n",
        "import time                            # Execution timing\n",
        "\n",
        "# Hardware configuration\n",
        "processing_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Processing will occur on: {processing_device}\")\n",
        "\n",
        "# Data paths configuration\n",
        "training_images_path = '/content/drive/MyDrive/soil-classification/soil_classification-2025/train'\n",
        "evaluation_images_path = '/content/drive/MyDrive/soil-classification/soil_classification-2025/test'\n",
        "\n",
        "# Loading data annotations\n",
        "training_annotations = pd.read_csv('/content/drive/MyDrive/soil-classification/soil_classification-2025/train_labels.csv')\n",
        "evaluation_annotations = pd.read_csv('/content/drive/MyDrive/soil-classification/soil_classification-2025/train_labels.csv')\n",
        "\n",
        "# Soil category encoding\n",
        "soil_category_encoding = {\n",
        "    'Alluvial soil': 0,\n",
        "    'Black Soil': 1,\n",
        "    'Clay soil': 2,\n",
        "    'Red soil': 3\n",
        "}\n",
        "\n",
        "reverse_soil_encoding = {v: k for k, v in soil_category_encoding.items()}\n",
        "\n",
        "# Apply encoding to training data\n",
        "training_annotations['encoded_label'] = training_annotations['soil_type'].map(soil_category_encoding)\n",
        "\n",
        "# Custom dataset handler\n",
        "class SoilImageDataset(Dataset):\n",
        "    def __init__(self, metadata, base_path, image_processor=None, evaluation_mode=False):\n",
        "        self.metadata = metadata\n",
        "        self.base_path = base_path\n",
        "        self.image_processor = image_processor\n",
        "        self.evaluation_mode = evaluation_mode\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.metadata)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_name = self.metadata.iloc[index, 0]\n",
        "        full_img_path = os.path.join(self.base_path, img_name)\n",
        "        img_data = Image.open(full_img_path).convert('RGB')\n",
        "\n",
        "        if self.image_processor:\n",
        "            img_data = self.image_processor(img_data)\n",
        "\n",
        "        if self.evaluation_mode:\n",
        "            return img_data, img_name\n",
        "        else:\n",
        "            category = self.metadata.iloc[index, -1]\n",
        "            return img_data, category\n",
        "\n",
        "# Image processing pipelines\n",
        "training_processing = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "evaluation_processing = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Dataset preparation\n",
        "training_dataset = SoilImageDataset(training_annotations, training_images_path, image_processor=training_processing)\n",
        "evaluation_dataset = SoilImageDataset(evaluation_annotations, evaluation_images_path, image_processor=evaluation_processing, evaluation_mode=True)\n",
        "\n",
        "# Data loading configuration\n",
        "training_data_loader = DataLoader(training_dataset, batch_size=32, shuffle=True)\n",
        "evaluation_data_loader = DataLoader(evaluation_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Model initialization\n",
        "soil_classifier = models.efficientnet_b0(pretrained=True)\n",
        "soil_classifier.classifier[1] = nn.Linear(soil_classifier.classifier[1].in_features, 4)\n",
        "soil_classifier = soil_classifier.to(processing_device)\n",
        "\n",
        "# Training configuration\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "model_optimizer = optim.AdamW(soil_classifier.parameters(), lr=0.0001)\n",
        "learning_adjuster = optim.lr_scheduler.StepLR(model_optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "# Model training process\n",
        "def execute_training(model, data_loader, total_epochs=20, early_stop_threshold=5):\n",
        "    optimal_weights = copy.deepcopy(model.state_dict())\n",
        "    best_performance = 0.0\n",
        "    patience_tracker = 0\n",
        "\n",
        "    for current_epoch in range(total_epochs):\n",
        "        model.train()\n",
        "        cumulative_loss = 0.0\n",
        "        predicted_values = []\n",
        "        actual_values = []\n",
        "\n",
        "        for batch_images, batch_labels in tqdm(data_loader, desc=f\"Training Epoch {current_epoch+1}/{total_epochs}\"):\n",
        "            batch_images, batch_labels = batch_images.to(processing_device), batch_labels.to(processing_device)\n",
        "            model_optimizer.zero_grad()\n",
        "\n",
        "            model_output = model(batch_images)\n",
        "            batch_loss = loss_function(model_output, batch_labels)\n",
        "            batch_loss.backward()\n",
        "            model_optimizer.step()\n",
        "\n",
        "            _, batch_predictions = torch.max(model_output, 1)\n",
        "            cumulative_loss += batch_loss.item()\n",
        "            predicted_values.extend(batch_predictions.cpu().numpy())\n",
        "            actual_values.extend(batch_labels.cpu().numpy())\n",
        "\n",
        "        performance_metrics = f1_score(actual_values, predicted_values, average=None)\n",
        "        minimum_f1 = min(performance_metrics)\n",
        "        print(f\"Epoch {current_epoch+1} - Total Loss: {cumulative_loss:.4f} | Class F1 Scores: {performance_metrics} | Minimum F1: {minimum_f1:.4f}\")\n",
        "\n",
        "        learning_adjuster.step()\n",
        "\n",
        "        if minimum_f1 > best_performance:\n",
        "            best_performance = minimum_f1\n",
        "            optimal_weights = copy.deepcopy(model.state_dict())\n",
        "            patience_tracker = 0\n",
        "            print(\"▲ Improved model weights saved!\")\n",
        "        else:\n",
        "            patience_tracker += 1\n",
        "            print(f\"▼ No improvement detected. Patience counter: {patience_tracker}/{early_stop_threshold}\")\n",
        "            if patience_tracker >= early_stop_threshold:\n",
        "                print(\"✋ Early stopping activated.\")\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(optimal_weights)\n",
        "    return model\n",
        "\n",
        "# Execute training\n",
        "soil_classifier = execute_training(soil_classifier, training_data_loader, total_epochs=20, early_stop_threshold=4)\n",
        "\n",
        "# Prepare evaluation data\n",
        "eval_image_list = [f for f in os.listdir(evaluation_images_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "eval_metadata = pd.DataFrame({'image_identifier': eval_image_list})\n",
        "\n",
        "eval_dataset = SoilImageDataset(eval_metadata, evaluation_images_path, image_processor=evaluation_processing, evaluation_mode=True)\n",
        "eval_loader = DataLoader(eval_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Prediction function\n",
        "def generate_predictions(model):\n",
        "    model.eval()\n",
        "    result_predictions = []\n",
        "    image_identifiers = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for input_images, img_ids in tqdm(eval_loader, desc=\"Generating Predictions\"):\n",
        "            input_images = input_images.to(processing_device)\n",
        "            model_results = model(input_images)\n",
        "            _, predicted_classes = torch.max(model_results, 1)\n",
        "            result_predictions.extend(predicted_classes.cpu().numpy())\n",
        "            image_identifiers.extend(img_ids)\n",
        "\n",
        "    predicted_categories = [reverse_soil_encoding[p] for p in result_predictions]\n",
        "    return pd.DataFrame({'image_id': image_identifiers, 'predicted_soil': predicted_categories})\n",
        "\n",
        "# Create results\n",
        "results_dataframe = generate_predictions(soil_classifier)\n",
        "\n",
        "# Organize results according to reference order\n",
        "reference_order = pd.read_csv('/content/drive/MyDrive/soil-classification/soil_classification-2025/test_ids.csv')\n",
        "\n",
        "reference_order['sort_index'] = range(len(reference_order))\n",
        "organized_results = pd.merge(reference_order, results_dataframe, on='image_id', how='left')\n",
        "organized_results = organized_results.sort_values(by='sort_index')\n",
        "\n",
        "# Save final output\n",
        "output_directory = 'working'\n",
        "if not os.path.exists(output_directory):\n",
        "    os.makedirs(output_directory)\n",
        "\n",
        "organized_results[['image_id', 'predicted_soil']].to_csv(os.path.join(output_directory, 'soil_predictions.csv'), index=False)\n",
        "print(\"✔ Prediction results successfully saved.\")\n",
        "\n",
        "# Download results\n",
        "from google.colab import files\n",
        "files.download(os.path.join(output_directory, 'soil_predictions.csv'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "collapsed": true,
        "id": "iozm3j9g-LQK",
        "outputId": "5bf31eda-bce6-4c78-ad26-a930ac5741ff"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing will occur on: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 93.6MB/s]\n",
            "Training Epoch 1/20: 100%|██████████| 39/39 [15:04<00:00, 23.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Total Loss: 33.9328 | Class F1 Scores: [0.80943026 0.70656371 0.66161616 0.7890625 ] | Minimum F1: 0.6616\n",
            "▲ Improved model weights saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 2/20: 100%|██████████| 39/39 [00:22<00:00,  1.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 - Total Loss: 13.5336 | Class F1 Scores: [0.91969407 0.90672451 0.84577114 0.95700935] | Minimum F1: 0.8458\n",
            "▲ Improved model weights saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 3/20: 100%|██████████| 39/39 [00:22<00:00,  1.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 - Total Loss: 8.3968 | Class F1 Scores: [0.94555874 0.92273731 0.8992629  0.95716946] | Minimum F1: 0.8993\n",
            "▲ Improved model weights saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 4/20: 100%|██████████| 39/39 [00:22<00:00,  1.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 - Total Loss: 6.2110 | Class F1 Scores: [0.95437262 0.94736842 0.91315136 0.97560976] | Minimum F1: 0.9132\n",
            "▲ Improved model weights saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 5/20: 100%|██████████| 39/39 [00:21<00:00,  1.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 - Total Loss: 5.3173 | Class F1 Scores: [0.96479543 0.96982759 0.91729323 0.98113208] | Minimum F1: 0.9173\n",
            "▲ Improved model weights saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 6/20: 100%|██████████| 39/39 [00:22<00:00,  1.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 - Total Loss: 5.4066 | Class F1 Scores: [0.9645933  0.96581197 0.94       0.96798493] | Minimum F1: 0.9400\n",
            "▲ Improved model weights saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 7/20: 100%|██████████| 39/39 [00:22<00:00,  1.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 - Total Loss: 5.1741 | Class F1 Scores: [0.9705603  0.97167756 0.945      0.96240602] | Minimum F1: 0.9450\n",
            "▲ Improved model weights saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 8/20: 100%|██████████| 39/39 [00:21<00:00,  1.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 - Total Loss: 3.8188 | Class F1 Scores: [0.98288973 0.98047722 0.97014925 0.9905482 ] | Minimum F1: 0.9701\n",
            "▲ Improved model weights saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 9/20: 100%|██████████| 39/39 [00:22<00:00,  1.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 - Total Loss: 3.4794 | Class F1 Scores: [0.98391675 0.97603486 0.96221662 0.97551789] | Minimum F1: 0.9622\n",
            "▼ No improvement detected. Patience counter: 1/4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 10/20: 100%|██████████| 39/39 [00:22<00:00,  1.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 - Total Loss: 4.1468 | Class F1 Scores: [0.97731569 0.98047722 0.96482412 0.9829222 ] | Minimum F1: 0.9648\n",
            "▼ No improvement detected. Patience counter: 2/4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 11/20: 100%|██████████| 39/39 [00:22<00:00,  1.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 - Total Loss: 4.2103 | Class F1 Scores: [0.9772296  0.96551724 0.96259352 0.9752381 ] | Minimum F1: 0.9626\n",
            "▼ No improvement detected. Patience counter: 3/4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Epoch 12/20: 100%|██████████| 39/39 [00:21<00:00,  1.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 - Total Loss: 3.2230 | Class F1 Scores: [0.97815764 0.98706897 0.96296296 0.98467433] | Minimum F1: 0.9630\n",
            "▼ No improvement detected. Patience counter: 4/4\n",
            "✋ Early stopping activated.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating Predictions: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔ Prediction results successfully saved.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_23db4d62-bb56-40f9-8646-9e8095af6c78\", \"soil_predictions.csv\", 9464)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}